{"cells":[{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import os\n","import torch\n","import torchvision\n","import torch.nn as nn # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n","import torchvision.datasets as datasets # Has standard datasets we can import in a nice way\n","import torchvision.transforms as transforms # Transformations we can perform on our dataset\n","import torch.nn.functional as F # All functions that don't have any parameters\n","from torch.utils.data import DataLoader, Dataset # Gives easier dataset managment and creates mini batches\n","from torchvision.datasets import ImageFolder\n","import torch.optim as optim # For all Optimization algorithms, SGD, Adam, etc.\n","from PIL import Image"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # use gpu or cpu"]},{"cell_type":"markdown","metadata":{},"source":["## train test split"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","dataset = ImageFolder(\"../input/cat-and-dog/training_set/training_set/\")\n","train_data, test_data, train_label, test_label = train_test_split(dataset.imgs, dataset.targets, test_size=0.2, random_state=42)\n","\n","# ImageLoader Class\n","\n","class ImageLoader(Dataset):\n","    def __init__(self, dataset, transform=None):\n","        self.dataset = self.checkChannel(dataset) # some images are CMYK, Grayscale, check only RGB \n","        self.transform = transform\n","    \n","    def __len__(self):\n","        return len(self.dataset)\n","    \n","    def __getitem__(self, item):\n","        image = Image.open(self.dataset[item][0])\n","        classCategory = self.dataset[item][1]\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, classCategory\n","        \n","    \n","    def checkChannel(self, dataset):\n","        datasetRGB = []\n","        for index in range(len(dataset)):\n","            if (Image.open(dataset[index][0]).getbands() == (\"R\", \"G\", \"B\")): # Check Channels\n","                datasetRGB.append(dataset[index])\n","        return datasetRGB"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_transform = transforms.Compose([\n","    transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize([0.5]*3, [0.5]*3)\n","]) # train transform\n","\n","test_transform = transforms.Compose([\n","    transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize([0.5]*3, [0.5]*3)\n","]) # test transform\n","\n","train_dataset = ImageLoader(train_data, train_transform)\n","test_dataset = ImageLoader(test_data, test_transform)"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","from torchvision import models\n","# load pretrain model and modify...\n","model = models.resnet50(pretrained=True)\n","\n","# If you want to do finetuning then set requires_grad = False\n","# Remove these two lines if you want to train entire model,\n","# and only want to load the pretrain weights.\n","\n","for param in model.parameters():\n","    param.requires_grad = False\n","\n","num_ftrs = model.fc.in_features\n","model.fc = nn.Linear(num_ftrs, 2)\n","\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.01)\n","\n","\n","# Train and test\n","\n","def train(num_epoch, model):\n","    for epoch in range(0, num_epoch):\n","#         current_loss = 0.0\n","#         current_corrects = 0\n","        losses = []\n","        model.train()\n","        loop = tqdm(enumerate(train_loader), total=len(train_loader)) # create a progress bar\n","        for batch_idx, (data, targets) in loop:\n","            data = data.to(device=device)\n","            targets = targets.to(device=device)\n","            scores = model(data)\n","            \n","            loss = criterion(scores, targets)\n","            optimizer.zero_grad()\n","            losses.append(loss)\n","            loss.backward()\n","            optimizer.step()\n","            _, preds = torch.max(scores, 1)\n","#             current_loss += loss.item() * data.size(0)\n","#             current_corrects += (preds == targets).sum().item()\n","#             accuracy = int(current_corrects / len(train_loader.dataset) * 100)\n","            loop.set_description(f\"Epoch {epoch+1}/{num_epoch} process: {int((batch_idx / len(train_loader)) * 100)}\")\n","            loop.set_postfix(loss=loss.data.item())\n","        \n","        # save model\n","        torch.save({ \n","                    'model_state_dict': model.state_dict(), \n","                    'optimizer_state_dict': optimizer.state_dict(), \n","                    }, 'checpoint_epoch_'+str(epoch)+'.pt')\n","\n","\n","        \n","# model.eval() is a kind of switch for some specific layers/parts of the model that behave differently,\n","# during training and inference (evaluating) time. For example, Dropouts Layers, BatchNorm Layers etc. \n","# You need to turn off them during model evaluation, and .eval() will do it for you. In addition, \n","# the common practice for evaluating/validation is using torch.no_grad() in pair with model.eval() \n","# to turn off gradients computation:\n","        \n","def test():\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for x, y in test_loader:\n","            x = x.to(device)\n","            y = y.to(device)\n","            output = model(x)\n","            _, predictions = torch.max(output, 1)\n","            correct += (predictions == y).sum().item()\n","            test_loss = criterion(output, y)\n","            \n","    test_loss /= len(test_loader.dataset)\n","    print(\"Average Loss: \", test_loss, \"  Accuracy: \", correct, \" / \",\n","    len(test_loader.dataset), \"  \", int(correct / len(test_loader.dataset) * 100), \"%\")"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["if __name__ == \"__main__\":\n","    train(5, model) # train\n","    test() # test"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(\"----> Loading checkpoint\")\n","checkpoint = torch.load(\"./checpoint_epoch_4.pt\") # Try to load last checkpoint\n","model.load_state_dict(checkpoint[\"model_state_dict\"]) \n","optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Check the test set\n","dataset = ImageFolder(\"../input/cat-and-dog/test_set/test_set/\", \n","                     transform=transforms.Compose([\n","                         transforms.Resize((224, 224)), \n","                         transforms.ToTensor(), \n","                         transforms.Normalize([0.5]*3, [0.5]*3)\n","                     ]))\n","print(dataset)\n","dataloader = DataLoader(dataset, batch_size=1, shuffle = False)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["# for j, (data, labels) in enumerate(dataloader):\n","with torch.no_grad():\n","    model.eval()\n","    for data, target in dataloader:\n","        data, target = data.to(device), target.to(device)\n","        output = model(data)\n","        _, predicted = torch.max(output, 1)\n","        print(f\"predicted ----> {predicted[0]}\")"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def RandomImagePrediction(filepath):\n","    img_array = Image.open(filepath).convert(\"RGB\")\n","    data_transforms=transforms.Compose([\n","        transforms.Resize((224, 224)), \n","        transforms.ToTensor(), \n","        transforms.Normalize([0.5]*3, [0.5]*3)\n","    ])\n","    img = data_transforms(img_array).unsqueeze(dim=0) # Returns a new tensor with a dimension of size one inserted at the specified position.\n","    load = DataLoader(img)\n","    \n","    for x in load:\n","        x=x.to(device)\n","        pred = model(x)\n","        _, preds = torch.max(pred, 1)\n","        print(f\"class : {preds}\")\n","        if preds[0] == 1: print(f\"predicted ----> Dog\")\n","        else: print(f\"predicted ----> Cat\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["if __name__ == \"__main__\":\n","    RandomImagePrediction(\"../input/prediction-pytorch/dog/d41586-020-01430-5_17977552.jpg\") # dog image\n","    RandomImagePrediction(\"../input/cat-and-dog/test_set/test_set/cats/cat.4011.jpg\") # cat image\n","    RandomImagePrediction(\"../input/prediction-pytorch/dog/322868_1100-1100x628.jpg\") # dog image"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":23777,"sourceId":30378,"sourceType":"datasetVersion"},{"datasetId":1078863,"sourceId":1815992,"sourceType":"datasetVersion"}],"dockerImageVersionId":30042,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
